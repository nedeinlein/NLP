{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework #3\n",
    "Nathan Deinlein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\nedei\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     C:\\Users\\nedei\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\nedei\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\nedei\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#package imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('brown')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('wordnet')\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import of sentences for question 2 and 3\n",
    "longsent = open(\"C:/Users/nedei/Downloads/POS tagger.txt\",encoding=\"utf8\").read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.\tRun one of the part-of-speech (POS) taggers available in Python. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a.\tFind the longest sentence you can, longer than 10 words, that the POS tagger tags correctly. Show the input and output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('It', 'PRP'), ('is', 'VBZ'), ('a', 'DT'), ('truth', 'NN'), ('universally', 'RB'), ('acknowledged', 'VBD'), (',', ','), ('that', 'IN'), ('a', 'DT'), ('single', 'JJ'), ('man', 'NN'), ('in', 'IN'), ('possession', 'NN'), ('of', 'IN'), ('a', 'DT'), ('good', 'JJ'), ('fortune', 'NN'), (',', ','), ('must', 'MD'), ('be', 'VB'), ('in', 'IN'), ('want', 'NN'), ('of', 'IN'), ('a', 'DT'), ('wife', 'NN'), ('.', '.'), ('However', 'RB'), ('little', 'JJ'), ('known', 'VBN'), ('the', 'DT'), ('feelings', 'NNS'), ('or', 'CC'), ('views', 'NNS'), ('of', 'IN'), ('such', 'JJ'), ('a', 'DT'), ('man', 'NN'), ('may', 'MD'), ('be', 'VB'), ('on', 'IN'), ('his', 'PRP$'), ('first', 'JJ'), ('entering', 'VBG'), ('a', 'DT'), ('neighbourhood', 'NN'), (',', ','), ('this', 'DT'), ('truth', 'NN'), ('is', 'VBZ'), ('so', 'RB'), ('well', 'RB'), ('fixed', 'VBN'), ('in', 'IN'), ('the', 'DT'), ('minds', 'NNS'), ('of', 'IN'), ('the', 'DT'), ('surrounding', 'VBG'), ('families', 'NNS'), (',', ','), ('that', 'IN'), ('he', 'PRP'), ('is', 'VBZ'), ('considered', 'VBN'), ('as', 'IN'), ('the', 'DT'), ('rightful', 'JJ'), ('property', 'NN'), ('of', 'IN'), ('some', 'DT'), ('one', 'CD'), ('or', 'CC'), ('other', 'JJ'), ('of', 'IN'), ('their', 'PRP$'), ('daughters', 'NNS'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "tokens = nltk.word_tokenize(longsent)\n",
    "for x in tokens:\n",
    "    tagged = nltk.pos_tag(tokens)\n",
    "\n",
    "print(tagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "LongestSentence = \"It is a truth universally acknowledged, that a single man in possession of a good fortune, must be in want of a wife.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b.\tFind the shortest sentence you can, shorter than 10 words, that the POS tagger fails to tag 100 percent correctly. Show the input and output. Explain your conjecture as to why the tagger might have been less than perfect with this sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('He', 'PRP'), ('wept', 'VBD'), ('.', '.'), ('I', 'PRP'), ('am', 'VBP'), ('.', '.'), ('Revelled', 'VBD'), ('he', 'PRP'), ('did', 'VBD'), ('.', '.'), ('He', 'PRP'), ('coloured', 'VBD'), ('it', 'PRP'), ('well', 'RB'), ('.', '.'), ('His', 'PRP$'), ('take', 'NN'), ('was', 'VBD'), ('great', 'JJ'), ('.', '.'), ('He', 'PRP'), ('is', 'VBZ'), ('to', 'TO'), ('take', 'VB'), ('possession', 'NN'), ('before', 'IN'), ('Michaelmas', 'NNP'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "shortsent = 'He wept. I am. Revelled he did. He coloured it well. His take was great. He is to take possession before Michaelmas.'\n",
    "stop_words = set(stopwords.words('english'))\n",
    "tokens = nltk.word_tokenize(shortsent)\n",
    "for x in tokens:\n",
    "    tagged = nltk.pos_tag(tokens)\n",
    "\n",
    "print(tagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ShortestSentence = \"He is to take possession before Michaelmas.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I purposely tried to confuse it by throwing in an infinitive verb phrase \"to take\" It doesn't look like that was an option in the selections unlike gerund or present participle which I follow similar rules."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 2.\tRun a different POS tagger in Python. Process the same two sentences from question 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('It', 'PRP'), ('is', 'VBZ'), ('a', 'DT'), ('truth', 'NN'), ('universally', 'RB'), ('acknowledged', 'VBD'), (',', ','), ('that', 'IN'), ('a', 'DT'), ('single', 'JJ'), ('man', 'NN'), ('in', 'IN'), ('possession', 'NN'), ('of', 'IN'), ('a', 'DT'), ('good', 'JJ'), ('fortune', 'NN'), (',', ','), ('must', 'MD'), ('be', 'VB'), ('in', 'IN'), ('want', 'NN'), ('of', 'IN'), ('a', 'DT'), ('wife', 'NN'), ('.', '.'), ('He', 'PRP'), ('is', 'VBZ'), ('to', 'TO'), ('take', 'VB'), ('possession', 'NN'), ('before', 'IN'), ('Michaelmas', 'NNP'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "#tagger 1\n",
    "sent2 = LongestSentence + \" \" + ShortestSentence\n",
    "\n",
    "tokens = nltk.word_tokenize(sent2)\n",
    "for x in tokens:\n",
    "    tagged = nltk.pos_tag(tokens)\n",
    "    \n",
    "print(tagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'It': 'PPS', 'is': 'BEZ', 'a': 'AT', 'truth': 'NN', 'universally': 'RB', 'acknowledged': 'VBD', ',': ',', 'that': 'CS', 'single': 'AP', 'man': 'NN', 'in': 'IN', 'possession': 'NN', 'of': 'IN', 'good': 'JJ', 'fortune': 'NN', 'must': 'MD', 'be': 'BE', 'want': 'VB', 'wife': 'NN', '.': '.', 'He': 'PPS', 'to': 'IN', 'take': 'VB', 'before': 'IN', 'Michaelmas': None}\n"
     ]
    }
   ],
   "source": [
    "#tagger 2\n",
    "from nltk.corpus import brown\n",
    "import collections\n",
    "from collections import defaultdict\n",
    "mytokens = nltk.word_tokenize(sent2)\n",
    "keys, tags = zip(*brown.tagged_words())\n",
    "tagger = dict(zip(keys, tags))\n",
    "newDict = dict()\n",
    "def filterTheDict(dictObj, tokens):\n",
    "    for token in tokens:\n",
    "        value = dictObj.get(token)\n",
    "        tempdict = {token:value}\n",
    "        newDict.update(tempdict)\n",
    "filterTheDict(tagger,mytokens)\n",
    "print(newDict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a.\tDoes it produce the same or different output?\n",
    "They are similar but there are some difference in categorizations of some of the words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b.\tExplain any differences as best you can.\n",
    "It actually looks like most of the difference seems to be in the nomenclature between the two different groups. Also Michaelmas was not identified in the Brown Corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.\tIn a news article from this weekâ€™s news, find a random sentence of at least 10 words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "news = '\"To put it simply Russia just announced that it is carving out a big chunk of Ukraine,\" Biden said on Tuesday.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a.\tLooking at the Penn tag set, manually POS tag the sentence yourself.\n",
    "tagged - (\",\"),(To,TO), (put,VB), (it,PRP), (simply,RB), (Russia,NNP), (just,RB), (announced,VBD), (that,IN), (it,PRP), (is,VB), (carving,VB), (out,RB), (a,DT), (big,RB), (chunk,NN), (of,IN), (Ukraine,NNP),(,,,),(\",\"), (Biden,NNP), (said,VBD),(on,IN),(Tuesday,NN),(.,.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b.\tNow run the same sentences through both taggers that you implemented for questions 1 and 2. Did either of the taggers produce the same results as you had created manually?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('``', '``'), ('To', 'TO'), ('put', 'VB'), ('it', 'PRP'), ('simply', 'RB'), ('Russia', 'NNP'), ('just', 'RB'), ('announced', 'VBD'), ('that', 'IN'), ('it', 'PRP'), ('is', 'VBZ'), ('carving', 'VBG'), ('out', 'RP'), ('a', 'DT'), ('big', 'JJ'), ('chunk', 'NN'), ('of', 'IN'), ('Ukraine', 'NNP'), (',', ','), (\"''\", \"''\"), ('Biden', 'NNP'), ('said', 'VBD'), ('on', 'IN'), ('Tuesday', 'NNP'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "#tagger1\n",
    "tokens = nltk.word_tokenize(news)\n",
    "for x in tokens:\n",
    "    tagged = nltk.pos_tag(tokens)\n",
    "    \n",
    "print(tagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'``': '``', 'To': 'TO', 'put': 'VBD', 'it': 'PPO', 'simply': 'RB', 'Russia': 'NP', 'just': 'RB', 'announced': 'VBN', 'that': 'CS', 'is': 'BEZ', 'carving': 'VBG', 'out': 'RP', 'a': 'AT', 'big': 'JJ', 'chunk': 'NN', 'of': 'IN', 'Ukraine': None, ',': ',', \"''\": \"''\", 'Biden': None, 'said': 'VBD', 'on': 'IN', 'Tuesday': 'NR', '.': '.'}\n"
     ]
    }
   ],
   "source": [
    "mytokens = nltk.word_tokenize(news)\n",
    "keys, tagg = zip(*brown.tagged_words())\n",
    "tagger = dict(zip(keys, tags))\n",
    "newDict = dict()\n",
    "def filterTheDict(dictObj, tokens):\n",
    "    for token in tokens:\n",
    "        value = dictObj.get(token)\n",
    "        tempdict = {token:value}\n",
    "        newDict.update(tempdict)\n",
    "filterTheDict(tagger,mytokens)\n",
    "print(newDict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c.\tExplain any differences between the two taggers and your manual tagging as much as you can.\n",
    "\n",
    "The main differences that I am seeing between the two taggers is a difference in names for the POS. Example being it in the first part of the sentence. There was also a disagreement on put with the second one saying that it was a past tense verb which is incorrect. I also have a disagreement between my tagging and tagger one stating that carving was a gerund. It is not. it is part of the verb phrase here. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
