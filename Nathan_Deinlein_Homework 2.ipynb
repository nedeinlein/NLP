{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework #2\n",
    "Nathan Deinlein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\nedei\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#package imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions defined\n",
    "def lexical_diversity(text):\n",
    "    return len(set(text))/ len(text)\n",
    "def vocabsize(text):\n",
    "    return len(set(text))\n",
    "def length(text):\n",
    "    return len(text)\n",
    "def longword(text):\n",
    "    filtered = [x for x in text if len(x) > 5]\n",
    "    return len(filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   vocabsize  lexical_diversity  length  longwords                    Title\n",
      "0       6692           0.117552   56928      13562          The Flying Girl\n",
      "1       7127           0.079050   90158      15608         Enchanted Castle\n",
      "2       8232           0.056334  146129      34049      Pride and Prejudice\n",
      "3       3880           0.101864   38090       6487      Alice in Wonderland\n",
      "4       5400           0.134855   40043       8208          Christmas Carol\n",
      "5       6106           0.098571   61945      10830                Peter Pan\n",
      "6       3959           0.227228   17423       4727  Legend Of Sleepy Hallow\n"
     ]
    }
   ],
   "source": [
    "#File importation\n",
    "file_content = open(\"C:/Users/nedei/Downloads/The Flying Girl.txt\",encoding=\"utf8\").read()\n",
    "file_content2 = open(\"C:/Users/nedei/Downloads/Enchanted Castle.txt\",encoding=\"utf8\").read()\n",
    "file_content3 = open(\"C:/Users/nedei/Downloads/pride and prejudice.txt\",encoding=\"utf8\").read()\n",
    "file_content4 = open(\"C:/Users/nedei/Downloads/Alice in Wonderland.txt\",encoding=\"utf8\").read()\n",
    "file_content5 = open(\"C:/Users/nedei/Downloads/Christmas Carol.txt\",encoding=\"utf8\").read()\n",
    "file_content6 = open(\"C:/Users/nedei/Downloads/Peter Pan.txt\",encoding=\"utf8\").read()\n",
    "file_content7 = open(\"C:/Users/nedei/Downloads/Legend of sleepy Hollow.txt\",encoding=\"utf8\").read()\n",
    "\n",
    "#Data frame creation\n",
    "files = [file_content,file_content2,file_content3,file_content4,file_content5,file_content6,file_content7]\n",
    "titles = ['The Flying Girl', 'Enchanted Castle','Pride and Prejudice','Alice in Wonderland','Christmas Carol','Peter Pan','Legend Of Sleepy Hallow']\n",
    "data = []\n",
    "columns = ['vocabsize','lexical_diversity','length', 'longwords']\n",
    "for x in files:\n",
    "    tokens = nltk.word_tokenize(x)\n",
    "    v = vocabsize(tokens)\n",
    "    ld = lexical_diversity(tokens)\n",
    "    leng = length(tokens)\n",
    "    lw = longword(tokens)\n",
    "    values = [v,ld,leng, lw]\n",
    "    zipped = zip(columns,values)\n",
    "    dictionary = dict(zipped)\n",
    "    data.append(dictionary)\n",
    "df = pd.DataFrame.from_dict(data)\n",
    "df['Title'] = pd.Series(titles,index = df.index)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### #1 In Python, create a method for scoring the vocabulary size of a text, and normalize the score from 0 to 1. It does not matter what method you use for normalization as long as you explain it in a short paragraph. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaled Data String:\n",
      " [[0.64613971]\n",
      " [0.74609375]\n",
      " [1.        ]\n",
      " [0.        ]\n",
      " [0.34926471]\n",
      " [0.51148897]\n",
      " [0.01815257]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>vocabsize</th>\n",
       "      <th>length</th>\n",
       "      <th>lexical_diversity</th>\n",
       "      <th>Scaled_Vocab_Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Flying Girl</td>\n",
       "      <td>6692</td>\n",
       "      <td>56928</td>\n",
       "      <td>0.117552</td>\n",
       "      <td>0.646140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Enchanted Castle</td>\n",
       "      <td>7127</td>\n",
       "      <td>90158</td>\n",
       "      <td>0.079050</td>\n",
       "      <td>0.746094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pride and Prejudice</td>\n",
       "      <td>8232</td>\n",
       "      <td>146129</td>\n",
       "      <td>0.056334</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alice in Wonderland</td>\n",
       "      <td>3880</td>\n",
       "      <td>38090</td>\n",
       "      <td>0.101864</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Christmas Carol</td>\n",
       "      <td>5400</td>\n",
       "      <td>40043</td>\n",
       "      <td>0.134855</td>\n",
       "      <td>0.349265</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Title  vocabsize  length  lexical_diversity  \\\n",
       "0      The Flying Girl       6692   56928           0.117552   \n",
       "1     Enchanted Castle       7127   90158           0.079050   \n",
       "2  Pride and Prejudice       8232  146129           0.056334   \n",
       "3  Alice in Wonderland       3880   38090           0.101864   \n",
       "4      Christmas Carol       5400   40043           0.134855   \n",
       "\n",
       "   Scaled_Vocab_Size  \n",
       "0           0.646140  \n",
       "1           0.746094  \n",
       "2           1.000000  \n",
       "3           0.000000  \n",
       "4           0.349265  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = df[['vocabsize']]\n",
    "scaler = MinMaxScaler()\n",
    "scaled_data = scaler.fit_transform(df2)\n",
    "print('Scaled Data String:\\n',scaled_data)\n",
    "scaled_data_list = scaled_data.tolist()\n",
    "df3 = df[['Title','vocabsize','length','lexical_diversity']]\n",
    "df3['Scaled_Vocab_Size'] = pd.Series(scaled_data_list, index = df3.index)\n",
    "df3['Scaled_Vocab_Size'] = df3['Scaled_Vocab_Size'].str.get(0)\n",
    "df3.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I pulled the vocabsize that we created from the first homework into a dataframe in my first step. I then pulled specifically that column from the data frame and used the MinMaxScaler to scale the scores from 0 to 1. This is shown below. I then recombinded with the original data to create a new dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### #2 After consulting section 3.2 in chapter 1 of Bird-Klein, create a method for scoring the long-word vocabulary size of a text, and likewise normalize (and explain) the scoring as in step 1 above.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaled Data String:\n",
      " [[0.3013096 ]\n",
      " [0.37108656]\n",
      " [1.        ]\n",
      " [0.06002319]\n",
      " [0.11871632]\n",
      " [0.20813723]\n",
      " [0.        ]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>vocabsize</th>\n",
       "      <th>length</th>\n",
       "      <th>lexical_diversity</th>\n",
       "      <th>Scaled_Vocab_Size</th>\n",
       "      <th>Scaled_Longwords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Flying Girl</td>\n",
       "      <td>6692</td>\n",
       "      <td>56928</td>\n",
       "      <td>0.117552</td>\n",
       "      <td>0.646140</td>\n",
       "      <td>0.301310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Enchanted Castle</td>\n",
       "      <td>7127</td>\n",
       "      <td>90158</td>\n",
       "      <td>0.079050</td>\n",
       "      <td>0.746094</td>\n",
       "      <td>0.371087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pride and Prejudice</td>\n",
       "      <td>8232</td>\n",
       "      <td>146129</td>\n",
       "      <td>0.056334</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alice in Wonderland</td>\n",
       "      <td>3880</td>\n",
       "      <td>38090</td>\n",
       "      <td>0.101864</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.060023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Christmas Carol</td>\n",
       "      <td>5400</td>\n",
       "      <td>40043</td>\n",
       "      <td>0.134855</td>\n",
       "      <td>0.349265</td>\n",
       "      <td>0.118716</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Title  vocabsize  length  lexical_diversity  \\\n",
       "0      The Flying Girl       6692   56928           0.117552   \n",
       "1     Enchanted Castle       7127   90158           0.079050   \n",
       "2  Pride and Prejudice       8232  146129           0.056334   \n",
       "3  Alice in Wonderland       3880   38090           0.101864   \n",
       "4      Christmas Carol       5400   40043           0.134855   \n",
       "\n",
       "   Scaled_Vocab_Size  Scaled_Longwords  \n",
       "0           0.646140          0.301310  \n",
       "1           0.746094          0.371087  \n",
       "2           1.000000          1.000000  \n",
       "3           0.000000          0.060023  \n",
       "4           0.349265          0.118716  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4 = df[['longwords']]\n",
    "scaler = MinMaxScaler()\n",
    "scaled_data = scaler.fit_transform(df4)\n",
    "print('Scaled Data String:\\n',scaled_data)\n",
    "scaled_data_list = scaled_data.tolist()\n",
    "df5 = df3[['Title','vocabsize','length','lexical_diversity','Scaled_Vocab_Size']]\n",
    "df5['Scaled_Longwords'] = pd.Series(scaled_data_list, index = df5.index)\n",
    "df5['Scaled_Longwords'] = df5['Scaled_Longwords'].str.get(0)\n",
    "df5.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### #3 Now create a “text difficulty score” by combining the lexical diversity score from homework 1, and your normalized score of vocabulary size and long-word vocabulary size, in equal weighting. Explain what you see when this score is applied to same graded texts you used in homework 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Title  vocabsize  length  lexical_diversity  \\\n",
      "0          The Flying Girl       6692   56928           0.117552   \n",
      "1         Enchanted Castle       7127   90158           0.079050   \n",
      "2      Pride and Prejudice       8232  146129           0.056334   \n",
      "3      Alice in Wonderland       3880   38090           0.101864   \n",
      "4          Christmas Carol       5400   40043           0.134855   \n",
      "5                Peter Pan       6106   61945           0.098571   \n",
      "6  Legend Of Sleepy Hallow       3959   17423           0.227228   \n",
      "\n",
      "   Scaled_Vocab_Size  Scaled_Longwords  Text_Difficulty_Score  \n",
      "0           0.646140          0.301310               1.065001  \n",
      "1           0.746094          0.371087               1.196230  \n",
      "2           1.000000          1.000000               2.056334  \n",
      "3           0.000000          0.060023               0.161887  \n",
      "4           0.349265          0.118716               0.602836  \n",
      "5           0.511489          0.208137               0.818198  \n",
      "6           0.018153          0.000000               0.245381  \n"
     ]
    }
   ],
   "source": [
    "df5['Text_Difficulty_Score'] = df5['lexical_diversity'] + df5['Scaled_Vocab_Size'] + df5['Scaled_Longwords']\n",
    "print(df5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Where before I was surprised that Pride and Prejudice was ranked as one of the easiest of these books to read due to its lexical diversity, when vocabsize and long words scaled are added it, it becomes the hardest of the books to read and Alice in wonderland that was ranked one of the harder books on lexical diversity, falls to one of the easiest. This makes sense as it was a book designed to be a childrens book."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
